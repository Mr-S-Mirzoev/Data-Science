{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ocp6o22qai6ojznfoaruq"
   },
   "source": [
    "Original paper: https://arxiv.org/abs/1806.00035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4d7cpo5lxu4pyku7fz0dl"
   },
   "source": [
    "# 0. Read real and generated images#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "as1al4mlbbjcftjbr4r71r"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yoke1i8uuuh3c07vf9ad"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "CHANNEL_NUM = 3\n",
    "PICTURE_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "h33uiffezunzi7plkkgj6e"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "class ParticleDataset():\n",
    "    def __init__(self, file):\n",
    "        self.data = np.load(file)\n",
    "        self.image = self.data['Pictures'].reshape(-1, CHANNEL_NUM*PICTURE_SIZE*PICTURE_SIZE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"Pictures\": self.image[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "32n3n2dvp7do6ui72yzxjp"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "real_data = ParticleDataset('real.npz')\n",
    "vae_data = ParticleDataset('vae.npz')\n",
    "gan_data = ParticleDataset('gan.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "lrtdjxcimo9s4l3iw89ji"
   },
   "source": [
    "Make sure that the values of real and generated data are of the same order - it is important for cooperative binarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "cencvym3sp5jf0ckzapma"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "print(np.min(real_data.image), np.max(real_data.image))\n",
    "print(np.min(gan_data.image), np.max(gan_data.image))\n",
    "print(np.min(vae_data.image), np.max(vae_data.image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "hb6yo6inzjn55xecc9qn9f"
   },
   "source": [
    "# 1. Binarize# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "d5ke86mwfgb75s69mkuupy"
   },
   "source": [
    "To understand how real and generated objects are close to each other, we need to choose a space of features in which we look these objects at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "8i4ncby0aswopzz9hiddx"
   },
   "source": [
    "We go the easiest way and take pixels' values as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jjnxl47tzpj0dti8bxawwc"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import math\n",
    "## function which map object to probability distribution ##\n",
    "\n",
    "def bin_counts (real_data, generated_data, number_of_bins=25):\n",
    "    # binirize real and generated data, plot histogram and found density function\n",
    "    return real_density, gen_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tqi29586jlc8m35urwshk"
   },
   "source": [
    "Create $\\alpha-$ and $\\beta-$ vectors as in\n",
    "\n",
    "$\\hat{PRD}(Q,P) = \\{(\\alpha(\\lambda), \\beta(\\lambda))| \\lambda \\in \\Lambda \\}$, where $\\Lambda = \\{\\tan (\\frac{i}{m+1} \\frac{\\pi}{2}) | i = 1, 2 ... m\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rmcbb39ynimnigj4u3ojb9"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def count_alpha_beta (real_density, gen_density, num_angles = 1000):\n",
    "    assert real_density.shape == gen_density.shape\n",
    "    alpha_vec = []\n",
    "    beta_vec = []\n",
    "    angles = np.linspace(1e-6, np.pi/2 - 1e-6, num=num_angles)\n",
    "    # you code\n",
    "    return alpha_vec, beta_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9p5z7t4biw9dtwjjgw0qc"
   },
   "source": [
    "For stability, take the average of several repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "f548asbrcepmn9wtfdtmbf"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def count_prd(reals, gens, repeat_number = 10):\n",
    "    vectors = [count_alpha_beta(reals, gens) for i in range(repeat_number)]\n",
    "    vectors = np.array(vectors).mean(axis=0)\n",
    "    print (vectors.shape)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u321yjs5nre0n0goz45xq"
   },
   "source": [
    "## 2. Apply it##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1fq0jv04wwj7ftb57eitcf"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "a, b = bin_counts(real_data.image, vae_data.image)\n",
    "c, d = bin_counts(real_data.image, gan_data.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xqrl0s371z0w30o5a5ldni"
   },
   "source": [
    "## 3. Make vectors for plot and plot ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2zyeedi9b9f6lsp1jzs88"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "data_for_plots = count_prd(a, b)\n",
    "data_for_plots2 = count_prd(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qwpvi9tgc48i017gnsdjk"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "fig = plt.figure(figsize=(2.5, 2.5), dpi=200)\n",
    "fig.add_subplot(111).tick_params(axis='both', which='major', labelsize=8)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.plot(data_for_plots[0], data_for_plots[1], label = \"VAE\")\n",
    "plt.plot(data_for_plots2[0], data_for_plots2[1], label = \"GAN\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "v1gczqvhsf3mmnecmjh6t"
   },
   "source": [
    "**What curves were obtained for the first(VAE) and the second(GAN) models? What can we say about the advantages and disadvantages of each model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9qu54n76hebjkiqsb47l6"
   },
   "outputs": [],
   "source": [
    "#type answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "npq8j6z4jx7d46fg0pzfww"
   },
   "source": [
    "## Bonus: about features' space##\n",
    "\n",
    "It is possible to transfer the picture-> embedding, for example, using the 1st part of the Inception network as a feature extraxtor. This embedding can be used for bin counts also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "nlxu1mp4vhlcjef5i1y7ms"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# if you came here and still alive, the implementation of idea above will give you extra points =)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notebookId": "5bbde2ec-6afa-495b-ab15-13319751f4c9"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

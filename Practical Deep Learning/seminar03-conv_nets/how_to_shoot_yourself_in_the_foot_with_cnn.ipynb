{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Yandex DataSphere Kernel",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "version": "3.7.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "name": "how_to_shoot_yourself_in_the_foot_with_cnn (4).ipynb",
      "provenance": []
    },
    "notebookId": "8f3ba1c3-68b2-462d-8050-ac7d2972fee2"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9knWAIelap5",
        "cellId": "24wzuqlj89wm4ahvxi57j",
        "trusted": true
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxAOHFvglszx",
        "cellId": "2w8bv2xmozhlclkrn7moo"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yandexdataschool/Practical_DL/blob/spring20/seminar3/how_to_shoot_yourself_in_the_foot_with_cnn.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W6k6Bullap_",
        "cellId": "0zngede38s1g2znau62g8d6"
      },
      "source": [
        "# assuming input shape [batch, 3, 64, 64]\n",
        "cnn = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=2048, kernel_size=(3,3)),\n",
        "    nn.Conv2d(in_channels=2048, out_channels=1024, kernel_size=(3,3)),\n",
        "    nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=(3,3)),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d((6,6)),\n",
        "    nn.Conv2d(in_channels=6, out_channels=32, kernel_size=(20,20)),\n",
        "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(20,20)),\n",
        "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(20,20)),\n",
        "    nn.Softmax(),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64, 256),\n",
        "    nn.Softmax(),\n",
        "    nn.Linear(256, 10),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Dropout(0.5)\n",
        "    \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellId": "7y09x5yxognh7glyjh1wk8",
        "trusted": true,
        "id": "c9i_Hj_ZhWIb"
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "tensor = torch.randn((16, 3, 64, 64), dtype=torch.float)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xydlW1NSlaqD",
        "cellId": "5yp82sztn9m6jnzw71tvs"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "# Book of grudges\n",
        "* Input channels are wrong literally half the time (after pooling, after flatten).\n",
        "* Too many filters for first 3x3 convolution - will lead to enormous matrix while there's just not enough relevant combinations of 3x3 images (overkill).\n",
        "* Usually the further you go, the more filters you need.\n",
        "* large filters (10x10 is generally a bad pactice, and you definitely need more than 10 of them\n",
        "* the second of 10x10 convolution gets 8x6x6 image as input, so it's technically unable to perform such convolution.\n",
        "* Softmax nonlinearity effectively makes only 1 or a few neurons from the entire layer to \"fire\", rendering 512-neuron layer almost useless. Softmax at the output layer is okay though\n",
        "* Dropout after probability prediciton is just lame. A few random classes get probability of 0, so your probabilities no longer sum to 1 and crossentropy goes -inf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E84fiu7ZlaqE",
        "cellId": "uwnr6ieobyxcbccqdaz1f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}